## DAY 13 ‚Äì Model Comparison & Feature Engineering (Databricks)

---

### Learn

- Training multiple machine learning models
- Comparing model performance using MLflow
- Feature engineering techniques
- Understanding feature importance
- Building Spark ML pipelines

---

### üõ†Ô∏è Tasks

1. Trained multiple machine learning models
2. Logged model parameters and metrics in MLflow
3. Compared model performance across runs
4. Performed feature engineering
5. Built a Spark ML pipeline
6. Selected the best-performing model

---

### üìù Practice

- Trained multiple models:
  - Linear Regression
  - Decision Tree Regressor
  - Random Forest Regressor
- Logged parameters, metrics, and models using MLflow
- Compared R¬≤ scores across different models
- Applied feature engineering techniques
- Extracted feature importance from tree-based models
- Built and executed a Spark ML pipeline
- Selected the best model based on evaluation metrics

---

### Output Screenshots

**Train & Compare Multiple Models (MLflow)**  
![Model Comparison](day13_Train_and_Compare_Multiple_Models_MLflow.png)

**Feature Importance (Tree-based Models)**  
![Feature Importance](day_13_Feature_Importance_Tree_based_models.png)

**Spark ML Pipeline**  
![Spark ML Pipeline](day13_Spark_ML_Pipeline.png)


---

### Key Takeaway

Comparing multiple models helps identify the most effective solution for a given problem.  
Feature engineering and MLflow-based experiment tracking improve model performance, reproducibility, and decision-making in Databricks machine learning workflows.

---

### Acknowledgement

This work is part of the **Databricks 14 Days AI Challenge**,  
organised by [Indian Data Club](https://indiandataclub.com/) and  
[Codebasics](https://codebasics.io/),  
and sponsored by [Databricks](https://www.databricks.com/).

**#DatabricksWithIDC**
